lines(y2, lty='2')
y2
y1
x = 1:100
y1 = log(x)
y2=x^(1/4)
y2
y1
y2=x^(1/5)
y2
x=1:100
y1 = log(x)
y2 = x^(0.0001)
plot(y2-y1)
plot(100000*y2-y1)
install.packages("rstan")
sd(y)
N=1000;
set.seed(10)
N=1000;
mu = 5;
sigma = 4;
y = rnorm(N,mu,sigma);
mean(y)
sd(y)
Niter = 1000 # number of MCMC iterations
out_mu = rep(NA,Niter); #vector to store the mu draws
out_sigma2 = rep(NA,Niter); #vector to store the sigma2 draws
mu = 20; # initial value for mu
xbar = mean(y) # sufficient stat for mu
alpha = N/2; # alpha parameter of the IGamma full conditional for sigma2
#Main loop of Gibbs Sampler
for (iter in 1:Niter){
# Store mu and sigma2 values
out_mu[iter] = mu
out_sigma2[iter] = sigma2
#update mu given sigma2 (and y)
mu = rnorm(1,xbar,sqrt(sigma2/N))
#update sigma2 given mu (and y)
beta = 0.5*sum((y-mu)^2);
sigma2  = 1/rgamma(1,alpha,beta);
}
set.seed(5)
N=1000;
beta = 1;
lambda = rgamma(1,2,beta);
lambda = rgamma(1,2,beta);
y = rpois(N,lambda);
mean(y)
lambda
out_lambda = rep(NA,Niter); #vector to store the mu draws
out_beta = rep(NA,Niter); #vector to store the sigma2 draws
lambda = 20; # initial value for mu
beta = 2; # initial value for sigma2
#Main loop of Gibbs Sampler
for (iter in 1:Niter){
# Store mu and sigma2 values
out_lambda[iter] = lambda
out_beta[iter] = beta
#update mu given sigma2 (and y)
lambda = gamma(1,2+sum(y),N+beta)
#update sigma2 given mu (and y)
beta = gamma(1, 3,1+lambda )
}
?gamma
#Main loop of Gibbs Sampler
for (iter in 1:Niter){
# Store mu and sigma2 values
out_lambda[iter] = lambda
out_beta[iter] = beta
#update mu given sigma2 (and y)
lambda = rgamma(1,2+sum(y),N+beta)
#update sigma2 given mu (and y)
beta = rgamma(1, 3,1+lambda )
}
print(paste('lambda', lambda))
print(paste('beta', beta))
beta = 1;
lambda = rgamma(1,2,beta);
lambda
Niter = 1000 # number of MCMC iterations
out_lambda = rep(NA,Niter); #vector to store the mu draws
lambda2 = 20; # initial value for mu
beta2 = 2; # initial value for sigma2
#Main loop of Gibbs Sampler
for (iter in 1:Niter){
# Store mu and sigma2 values
out_lambda[iter] = lambda2
out_beta[iter] = beta2
#update mu given sigma2 (and y)
lambda2 = rgamma(1,2+sum(y),N+beta2)
#update sigma2 given mu (and y)
beta2 = rgamma(1, 3,1+lambda2 )
}
print(paste('lambda', lambda2))
print(paste('beta', beta2))
print(paste('lambda', lambda2,'original',lambda))
print(paste('beta', beta2, 'original', beta))
set.seed(5)
N=1000;
beta = 1;
lambda = rgamma(1,2,beta);
y = rpois(N,lambda);
mean(y)
lambda
Niter = 1000 # number of MCMC iterations
out_lambda = rep(NA,Niter); #vector to store the mu draws
out_beta = rep(NA,Niter); #vector to store the sigma2 draws
lambda2 = 20; # initial value for mu
beta2 = 2; # ini
#Main loop of Gibbs Sampler
for (iter in 1:Niter){
# Store mu and sigma2 values
out_lambda[iter] = lambda2
out_beta[iter] = beta2
#update mu given sigma2 (and y)
lambda2 = rgamma(1,2+sum(y),N+beta2)
#update sigma2 given mu (and y)
beta2 = rgamma(1, 3,1+lambda2 )
}
print(paste('lambda', lambda2,'original',lambda))
print(paste('beta', beta2, 'original', beta))
#Main loop of Gibbs Sampler
for (iter in 1:Niter){
# Store mu and sigma2 values
out_lambda[iter] = lambda2
out_beta[iter] = beta2
#update mu given sigma2 (and y)
lambda2 = rgamma(1,2+sum(y),N+beta2)
#update sigma2 given mu (and y)
beta2 = rgamma(1, 3,1+lambda2)
}
print(paste('lambda', lambda2,'original',lambda))
print(paste('beta', beta2, 'original', beta))
beta2 = 0.9; # initial value for sigma2
#Main loop of Gibbs Sampler
for (iter in 1:Niter){
# Store mu and sigma2 values
out_lambda[iter] = lambda2
out_beta[iter] = beta2
#update mu given sigma2 (and y)
lambda2 = rgamma(1,2+sum(y),N+beta2)
#update sigma2 given mu (and y)
beta2 = rgamma(1, 3,1+lambda2)
}
print(paste('lambda', lambda2,'original',lambda))
print(paste('beta', beta2, 'original', beta))
rgamma(1, 3,1+lambda2)
rgamma(1, 3,1+lambda2)
rgamma(1, 3,1+lambda2)
plot(out_lambda,type='l')
plot(out_beta,type = 'l')
print(c(mean(out_lambda),median(out_lambda),quantile(out_lambda,probs=c(0.025,0.975))))
print(c(mean(out_beta),median(out_beta),quantile(out_beta,probs=c(0.025,0.975))))
beta
library("rstan")
install.packages("rstan")
install.packages("C:/Users/test/AppData/Local/Temp/RtmpsH1u8A/downloaded_packages/rstan_2.21.7.tar.gz", repos = NULL, type = "source")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(broom)
library(modelr)
library(glmnet)
library(selectiveInference)
install.packages('selectiveInference')
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(broom)
library(modelr)
library(glmnet)
library(selectiveInference)
theme_set(theme_minimal(base_size = 20))
set.seed(12345678)
n <- 100
p <- 200
X <- matrix(rnorm(n*p), nrow = n)
Y <- rnorm(n)
# beta = c(rep(1,10), rep(0, p - 10))
# Y = X %*% beta + rnorm(n)
fitted_model = glmnet(X,Y)
plot(fitted_model)
?glmnet
set.seed(654321)
cv_fit = cv.glmnet(X, Y)
plot(cv_fit)
# typical shape?
# cv_fit
set.seed(12345678)
n <- 100
p <- 200
X <- matrix(rnorm(n*p), nrow = n)
Y <- rnorm(n)
beta = c(rep(1,10), rep(0, p - 10))
Y = X %*% beta + rnorm(n)
fitted_model = glmnet(X,Y)
plot(fitted_model)
set.seed(654321)
cv_fit = cv.glmnet(X, Y)
plot(cv_fit)
# typical shape?
# cv_fit
cv_fit
active_set = which(coef(fitted_model, s = cv_fit$lambda.1se)[-1] !=0)
active_set
X_reduced = X[, active_set]
dim(X_reduced)
lm_fit = lm(Y ~ X_reduced)
summary(lm_fit)
# Compute lasso path
# while storing information required for
# conditional (truncated) inference
lasso_path <- lar(X, Y)
# Use AIC/BIC to choose model size
# and compute adjusted p-values
# in higher dimensions change mult
# to log(n) for BIC, log(p) for RIC
lasso_inference <- larInf(lasso_path, mult = 2, type = "aic", ntimes = 1)
lasso_inference
# lasso_inference <- larInf(lasso_path, mult = 2, type = "aic", ntimes = 1, sigma = 0.15)
# lasso_inference
set.seed(123456789) # delete this line
high_dim_MSE_MC(n = 100, p = 100, instances = 50)
instance <- function(X, L, n, p, beta, mu) {
# Add noise to signal
Y <- mu + rnorm(n)
y <- Y - mean(Y)
# Fit model with glmnet
ridge_fit <- glmnet(X, y, standardize = TRUE, intercept = FALSE, alpha = 0, lambda = L)
# Extract estimate coefficients
beta_mat <- coef(ridge_fit)[-1, ]
# Compute MSE using true beta
MSEs <- apply(beta_mat, 2, function(beta_hat) sum((beta_hat - beta)^2))
out <- as.numeric(MSEs)
names(out) <- L
out
}
high_dim_MSE_MC <- function(n, p, instances = 10) {
## Generating signal
# A random sparse coefficient vector
beta <- rnorm(p) * rpois(p, 1) * rbinom(p, 1, .5)
# Fixed design matrix and mean
X <- matrix(rnorm(n*p), nrow = n)
mu <- X %*% beta
# Lambda grid
L <- exp(seq(
from = log(max(n, p, sum(beta^2))),
to = log(1e-3), length.out = n))
## Generate many noise instances
# tidyverse version of replicate()
output <- tibble(inst = 1:instances) %>%
mutate(MSEs = map(inst, ~instance(X, L, n, p, beta, mu)))
## Transform output to long data.frame
out_df <- output %>%
unnest_longer("MSEs") %>%
mutate(MSEs_id = as.numeric(MSEs_id))
names(out_df) <- c("instance", "MSE", "lambda")
## Plot results
out_df %>%
ggplot(aes(lambda, MSE)) +
ggtitle(bquote(
list(sparsity == .(sum(beta != 0)),
abs(abs(beta))^2 == .(round(sum(beta^2), 2)))
)) +
geom_line(aes(group = factor(instance)),
alpha = .2,
show.legend = FALSE) +
scale_x_log10()
}
set.seed(123456789) # delete this line
high_dim_MSE_MC(n = 100, p = 100, instances = 50)
#!/sw/arcts/centos7/stacks/gcc/8.2.0/R/4.1.0/bin/Rscript
library(data.table)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(ggbreak)
library("ggsci")
if(Sys.info()["nodename"] %in% c("PC-20181212HEBU")){
curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/tuneK_iterations/value"
setwd(curr_dir)
} else{ # greatlakes
curr_dir <- "/home/mengbing/research/RL_nonstationary/code2/simulation_nonstationary_changept_detection/output"
setwd(curr_dir)
}
N <- 50
set.seed(20)
dat <- fread("vall_2022-11-05N50_diffsign.csv")
dat <- fread("vall_2023-04-21N50_1d.csv")
dat
colMeans(dat)
colMeans(dat$`Discounted Value`)
mean(dat$`Discounted Value`)
# curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/tuneK_iterations/value"
curr_dir <- "C:/Users/test/Dropbox/tml/IHS/simu/simu/output/value"
setwd(curr_dir)
if(Sys.info()["nodename"] %in% c("PC-20181212HEBU")){
# curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/tuneK_iterations/value"
curr_dir <- "C:/Users/test/Dropbox/tml/IHS/simu/simu/output/value"
setwd(curr_dir)
} else{ # greatlakes
curr_dir <- "/home/mengbing/research/RL_nonstationary/code2/simulation_nonstationary_changept_detection/output"
setwd(curr_dir)
}
if(Sys.info()["nodename"] %in% c("PC-20181212HEBU")){
# curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/tuneK_iterations/value"
curr_dir <- "C:/Users/test/Dropbox/tml/IHS/simu/simu/output/value"
setwd(curr_dir)
} else{ # greatlakes
curr_dir <- "/home/mengbing/research/RL_nonstationary/code2/simulation_nonstationary_changept_detection/output"
setwd(curr_dir)
}
###################
if(Sys.info()["nodename"] %in% c("PC-20181212HEBU")){
curr_dir <- "C:/Users/test/Dropbox/tml/IHS/simu/simu/output/value"
setwd(curr_dir)
} else{ # greatlakes
curr_dir <- "/home/mengbing/research/RL_nonstationary/code2/simulation_nonstationary_changept_detection/output"
setwd(curr_dir)
}
Sys.info()["nodename"]
(Sys.info()["nodename"] %in% c("PC-20181212HEBU"))
# curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/tuneK_iterations/value"
curr_dir <- "C:/Users/test/Dropbox/tml/IHS/simu/simu/output/value"
setwd(curr_dir)
# curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/tuneK_iterations/value"
curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/output/value"
setwd(curr_dir)
dat2 <- fread("vall_2022-11-06N50_diffsign.csv")
dat2 <- fread("vall_2022-11-05N50_diffsign.csv")
mean(dat2$`Discounted Value`)
dat2
mean(dat2$`Discounted Value`[dat2$Setting == "pwconst2"])
mean(dat2$`Discounted Value`[dat2$Setting == "pwconst2" && dat2$init == "proposed"])
dat2$Setting == "pwconst2" && dat2$init == "proposed"
dat2$Setting == "pwconst2" & dat2$init == "proposed"
mean(dat2$`Discounted Value`[dat2$Setting == "pwconst2" & dat2$init == "proposed"])
dat
library(data.table)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(ggbreak)
library("ggsci")
if(Sys.info()["nodename"] %in% c("PC-20181212HEBU")){
curr_dir <- "C:/Users/test/Dropbox/tml/IHS/simu/simu/output/value"
setwd(curr_dir)
} else{ # greatlakes
curr_dir <- "/home/mengbing/research/RL_nonstationary/code2/simulation_nonstationary_changept_detection/output"
setwd(curr_dir)
}
N <- 50
set.seed(20)
dat <- fread("vall_2022-11-05N50_diffsign.csv")
curr_dir <- "C:/Users/test/Dropbox/tml/IHS/simu/simu/output/value"
setwd(curr_dir)
curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/tuneK_iterations/value"
setwd(curr_dir)
N <- 50
set.seed(20)
dat <- fread("vall_2022-11-05N50_diffsign.csv")
dat2 <- fread("vall_2023-04-22N50_1d.csv")
dat$Setting <- factor(dat$Setting,
levels = c('pwconst2', 'smooth'),
labels = c('Piecewise Constant', 'Smooth'))
dat <- fread("vall_2022-11-05N50_diffsign.csv")
dat2 <- fread("vall_2023-04-22N50_1d.csv")
head(dat)
dat[dat$init == 'proposed', ] = dat2[dat2$init == 'proposed',]
dat$init
dat[dat$init == 'only_clusters', ] = dat2[dat2$init == 'only_clusters',]
dat$Setting <- factor(dat$Setting,
levels = c('pwconst2', 'smooth'),
labels = c('Piecewise Constant', 'Smooth'))
dat[,'Average Value'] = dat[,'Average Value'] * 10
my_colors=c('#cc0c00', '#5c88da','#84bd00', '#ffcc00', '#7c878e','#00b5e2','#00af66',"#E69F00","#660099")
dat$init = factor(dat$init, levels = c("proposed", "oracle", "overall", "only_cp","only_clusters"),
labels  = c("Proposed", "Oracle", "DH", "Homongeneous", "Stationary"))
p_diff_av_value <- ggboxplot(dat,x='init', y = 'Average Value',fill = 'init', alpha=0.8,
ylab="Average Value", xlab="",lwd=1, fatten=1,
facet.by = c('Setting'),alpha=0.8,palette = my_colors[1:5],
ggtheme = theme(
# legend.direction="vertical",
# legend.position = "None",
legend.position = "bottom",
legend.text = element_text(size=16),
legend.margin=margin(t = 0, unit='cm'),
legend.box.margin=margin(-30,0,0,0),
panel.border = element_rect(color = "black", fill = NA, size = 1),
# axis.line=element_line(size=1, colour="black"),
panel.grid.major=element_line(colour="#d3d3d3"),
panel.grid.minor=element_line(colour="#d3d3d3"),
panel.background=element_blank(),
plot.title=element_text(size=18, face="bold"),
text=element_text(size=16),
# axis.text.x = element_blank(),
axis.text.x=element_text(colour="white", size=0, angle = 0),
# strip.text.y = element_blank(),
axis.text.y=element_text(colour="black", size=16),
plot.margin=grid::unit(c(0.3,0,0,0), "mm")
))#+
# geom_hline(yintercept = 0, size = 1, linetype="dashed", color = "red")
p_diff_av_value=ggpar(p_diff_av_value, legend.title = "")
p_diff_av_value
ggsave(paste0("diff_av_value", Sys.Date(), ".pdf"), width = 14, height = 2.5)
#!/sw/arcts/centos7/stacks/gcc/8.2.0/R/4.1.0/bin/Rscript
library(data.table)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggbreak)
library(RColorBrewer)
library("ggsci")
args = commandArgs(trailingOnly=TRUE)
curr_dir <- "C:/Users/test/Dropbox/tml/IHS/simu/simu/tuneK_iterations/final_perf"
setwd(curr_dir)
curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/tuneK_iterations/final_perf"
setwd(curr_dir)
N <- 50
curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/tuneK_iterations/final_perf"
setwd(curr_dir)
N <- 50
## KMeans
dat_km =fread('icmodel_2022-11-02method(7)N50_1d.csv')
dat_km
dat_tuneK = fread('tuneK_iter_2023-04-24N50_1d.csv')
dat_km[dat_km$init == 'best_model', ] = dat_tuneK[dat_tuneK$init == 'best_model',]
dat_tuneK
dat_tuneK = fread('tuneK_iter_2023-04-24N50_1d.csv')
dat_km[dat_km$init == 'best_model', ] = dat_tuneK[dat_tuneK$init == 'best_model',]
dat_km
dat_tuneK
dat_km$init <- factor(dat_km$init, levels = c( 'best_model', 'kmeans_K1', 'kmeans_K2', 'kmeans_K3', 'kmeans_K4'),
labels = c('Model Selected via the Information Criterion','K=1', 'K=2', 'K=3', 'K=4'))
dat_km$Setting <- factor(dat_km$Setting,
levels = c('pwconst2', 'smooth'),
labels = c('Piecewise Constant', 'Smooth'))
dat2_processed <- gather(dat_km, metric, value, -c('Setting', 'seed', 'init'))
dat2_processed$metric=factor(dat2_processed$metric, levels = c('cp_err', 'ARI'),
labels =  c('CP Error', 'ARI'))
cbPalette=c('#cc0c00', '#5c88da','#84bd00', '#ffcc00', '#7c878e','#00b5e2','#00af66',"#E69F00","#660099")
p2 <- ggplot(dat2_processed, aes(init, value, fill=init)) + #, color=`Effect Size`
geom_boxplot(lwd=1, fatten=1, alpha=0.8) +
labs(fill='') +
xlab("") +
ylab("Estimation Performance") +
# labs(fill="Method") +
theme(
# legend.direction="vertical",
legend.position = "bottom",
# panel.border=element_blank(),
# legend.box.spacing=0.4,
panel.border = element_rect(color = "black", fill = NA, size = 1),
# axis.line=element_line(size=1, colour="black"),
panel.grid.major=element_line(colour="#d3d3d3"),
panel.grid.minor=element_line(colour="#d3d3d3"),
panel.background=element_blank(),
plot.title=element_text(size=20, face="bold"),
text=element_text(size=18),
legend.text=element_text(size=18),
# axis.text.x=element_text(colour="black", size=16, angle = 90),
# axis.text.x = element_blank(),
axis.text.x = element_text(colour="white", size=0),
axis.text.y=element_text(colour="black", size=16),
plot.margin=grid::unit(c(0.3,0,-2,0), "mm")
) +
facet_grid(facets =metric~ Setting, scales = 'free_y')
p2 +scale_fill_startrek()
ggsave(paste0("offlineIC_k",Sys.Date(), ".pdf"), width = 14, height = 5)
curr_dir <- "C:/Users/test/Dropbox/tml/IHS/simu/simu/output/value"
setwd(curr_dir)
curr_dir <- "C:/Users/test/Dropbox/DIRL/IHS/simu/simu/tuneK_iterations/value_samesign"
setwd(curr_dir)
N <- 50
set.seed(20)
dat <- fread("vall_2022-11-06N50_samesign.csv")
dat2 <- fread('vall_2023-04-25N50_1d.csv')
dat[dat$init == 'proposed', ] = dat2[dat2$init == 'proposed',]
dat[dat$init == 'only_cluster', ] = dat[dat$init == 'only_cluster',]
dat$Setting <- factor(dat$Setting,
levels = c('pwconst2', 'smooth'),
labels = c('Piecewise Constant', 'Smooth'))
dat[,'Average Value'] = dat[,'Average Value'] * 10
dat$init = factor(dat$init, levels = c("proposed", "oracle", "overall", "only_cp","only_clusters"),
labels  = c("Proposed", "Oracle", "DH", "Homongeneous", "Stationary"))
cbPalette=c('#cc0c00', '#5c88da','#84bd00', '#ffcc00', '#7c878e','#00b5e2','#00af66',"#E69F00","#660099")
p_same_av_value <- ggboxplot(dat,x='init', y = 'Average Value',fill = 'init', alpha=0.8,
ylab="Average Value", xlab="",lwd=1, fatten=1,
facet.by = c('Setting'),alpha=0.8,palette = my_colors[1:5],
ggtheme = theme(
# legend.direction="vertical",
# legend.position = "None",
legend.position = "bottom",
legend.text = element_text(size=16),
legend.margin=margin(t = 0, unit='cm'),
legend.box.margin=margin(-30,0,0,0),
panel.border = element_rect(color = "black", fill = NA, size = 1),
# axis.line=element_line(size=1, colour="black"),
panel.grid.major=element_line(colour="#d3d3d3"),
panel.grid.minor=element_line(colour="#d3d3d3"),
panel.background=element_blank(),
plot.title=element_text(size=18, face="bold"),
text=element_text(size=16),
# axis.text.x = element_blank(),
axis.text.x=element_text(colour="white", size=0, angle = 0),
# strip.text.y = element_blank(),
axis.text.y=element_text(colour="black", size=16),
plot.margin=grid::unit(c(0.3,0,0,0), "mm")
))#+
# geom_hline(yintercept = 0, size = 1, linetype="dashed", color = "red")
p_same_av_value=ggpar(p_same_av_value, legend.title = "")
p_same_av_value
ggsave(paste0("same_av_value", Sys.Date(), ".pdf"), width = 14, height = 2.5)
